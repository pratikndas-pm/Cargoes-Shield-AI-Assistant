# ğŸš¢ Cargoes Shield â€“ AI Risk & Quoting Assistant

> AI-powered quoting and risk intelligence platform built on top of Cargoes ecosystem.  
> Designed to automate insurance policy evaluation, premium recommendations, and claim risk scoring.

---

## ğŸ“Š Overview
**Goal:** Automate marine insurance quote generation using LLMs and data-driven risk prediction.  
**Outcome:** Reduced quote turnaround time by 65% and increased clause retrieval accuracy by 32%.

---

## ğŸ§± Architecture Snapshot
| Layer | Description | Technology |
|--------|--------------|-------------|
| Data | Policy documents, historical claims, tariff sheets | Azure SQL, Databricks |
| Model | LLM with retrieval (RAG), risk scoring | GPT-4o, LangChain |
| API | Policy, Quoting, CRM | REST, Azure Functions |
| UI | Shield Assistant Dashboard | Streamlit / React |


---

## ğŸ§© Documentation Index
| Artifact | Description | Link |
|-----------|--------------|------|
| ğŸ“˜ PRD | Full product requirements document with objectives, success metrics, scope | [View PRD](./docs/PRD.md)
| ğŸ§¾ User Stories | Gherkin-format stories aligned to Jira tickets | [View User Stories](./docs/UserStories.md) |
| âœ… Testing Criteria | Model testing, functional test cases, QA validation flows | [View Testing Criteria](./docs/TestingCriteria.md) |
| ğŸ¨ Frontend & Model Guidelines | Design specs + LLM prompt engineering standards | [View Frontend Guide](./docs/Frontend_Model_Guidelines.md) |

---

## ğŸ§  Core Features
- ğŸ§© AI-driven quote and premium engine  
- ğŸ“„ Policy clause retrieval via RAG  
- âš™ï¸ Multi-insurer comparison and optimization  
- ğŸ”’ Compliance with WCO / UN/CEFACT standards  
- ğŸ“Š Dashboard with predictive claim scoring  

---

## ğŸ§® Example Use Case
**User Query:**  
> â€œGenerate a quote for refrigerated cargo from Singapore to Jebel Ali, 5 containers, high-risk category.â€

**Response:**  
- Risk Score: 7.8/10  
- Recommended Premium: USD 3,920  
- Policy Clauses: WCO-A12, Shield-7B, MarineHazard-02  
- ETA: 3 days  

---


### ğŸ’° Revenue & Commercial KPIs

| KPI | Definition | Target | Data Source |
|------|-------------|---------|--------------|
| **Total Premiums Processed (AED)** | Total value of all insurance policies purchased through Cargoes Shield. | â‰¥ AED **10M / month** | Payment Gateway / CRM |
| **Average Policy Value (AED)** | Mean value per issued policy across all providers. | â‰¥ **5,000 AED** | CRM / Finance DB |
| **Quote-to-Policy Conversion Rate** | Percentage of quotes that convert into paid policies. | â‰¥ **35%** | Analytics / CRM |
| **Gross Written Premium (GWP)** | Total premiums booked before deductions. | â‰¥ **AED 120M / Year** | Finance Reports |
| **Commission Margin per Policy (%)** | Net revenue margin after insurer commissions. | â‰¥ **12%** | Financial Ledger |
| **Underwriter Approval SLA** | Average time from AI quote to final underwriter approval. | â‰¤ **15 minutes** | Underwriter Console Logs |
| **Payment Success Rate** | Percentage of successful transactions out of all payment attempts. | â‰¥ **98%** | Payment Gateway Logs |
| **Refund / Failure Rate (%)** | Ratio of failed or refunded transactions to total transactions. | â‰¤ **1%** | Finance & Payment Reports |
| **Renewal Retention Rate** | Percentage of users renewing policies within 15 days of expiry. | â‰¥ **75%** | CRM / Renewal Module |
| **Active Insurer Partnerships** | Number of insurer APIs actively integrated and quoting. | â‰¥ **5** by Q1 | Integration Dashboard |

> ğŸ’¡ *Objective:* These KPIs measure the financial health, operational speed, and transaction reliability of the Cargoes Shield AI quoting and booking ecosystem.

### ğŸ¤– Model & AI Performance KPIs

| KPI | Definition | Target | Data Source |
|------|-------------|---------|--------------|
| **Precision@k** | Measures how accurately the AI retrieves relevant policy or quote information within the top-k responses. | â‰¥ **0.85** | ModelOps Validation Suite |
| **Recall** | Percentage of all relevant answers or quotes correctly retrieved by the AI. | â‰¥ **0.80** | Model Evaluation Reports |
| **F1 Score** | Combined measure of precision and recall for balanced model performance. | â‰¥ **0.82** | Model Testing Dashboard |
| **Latency (p95)** | 95th percentile of AI response time per query (user-perceived). | â‰¤ **2.5 seconds** | API Gateway Metrics |
| **AI Response Helpfulness Rate** | Percentage of AI responses rated â€œHelpfulâ€ by users. | â‰¥ **85%** | Feedback Logs |
| **Model Drift Rate** | Month-over-month drop in model accuracy due to outdated data or context. | â‰¤ **3%** | Model Monitoring Reports |
| **Retraining Frequency** | Frequency of scheduled model retraining to maintain accuracy and reduce drift. | Every **30 days** | MLOps Pipeline |
| **Feedback Incorporation Rate** | Percentage of low-rated AI responses used in retraining datasets. | â‰¥ **70%** | Feedback Data Pipeline |
| **Average Confidence Score (AI Answers)** | Mean confidence level returned by the model per answer or quote. | â‰¥ **0.90** | Model Inference Logs |
| **Model Explainability Coverage** | Percentage of AI responses with cited sources or document references. | 100% | AI Audit Logs |

> âš™ï¸ *Objective:* Maintain high trust, transparency, and predictability in AI-driven recommendations by balancing accuracy, latency, and explainability.

---

## ğŸ§© Diagram
<img width="1536" height="1024" alt="image" src="https://github.com/user-attachments/assets/3997655e-7e2d-4e1d-b581-9ef03707df7c" />
